{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awuiAESnsq62"
      },
      "source": [
        "## Team Tracking System\n",
        "\n",
        "We are developing a team tracking system for a medium-sized company to help managers keep track of their team's tasks, projects, and performance. The system aims to enhance communication, productivity, and decision-making among managers and their teams.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4RMqFc1VU704"
      },
      "outputs": [],
      "source": [
        "from secret_key import openai_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Mc9PBp1j36oU"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
        "from langchain.chains.router import MultiPromptChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X8V7HWVOU2KL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "70UH-WD7VGS8"
      },
      "outputs": [],
      "source": [
        "# account for deprecation of LLM model\n",
        "import datetime\n",
        "# Get the current date\n",
        "current_date = datetime.datetime.now().date()\n",
        "\n",
        "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
        "target_date = datetime.date(2024, 6, 12)\n",
        "\n",
        "# Set the model variable based on the current date\n",
        "if current_date > target_date:\n",
        "    llm_model = \"gpt-3.5-turbo\"\n",
        "else:\n",
        "    llm_model = \"gpt-3.5-turbo-0301\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gvDZzSqIPOC"
      },
      "source": [
        "#### 1: Generate a title for team tracking system\n",
        "Using LLM Chain to generate creative content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "duhb3alOEmR0"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4dVDqujdOEHE"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name or title to describe \\\n",
        "    a {product}?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s83QRPvBOPt9"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QDxXC57wOSpy",
        "outputId": "f0ad3550-9433-41bc-c924-6c3035f59cc7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Team Performance Tracker'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "product = 'Team Tracking System'\n",
        "chain.run(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl6AOfHrOmTr"
      },
      "source": [
        "#### 2: Generating marketing content for promoting the system's features using Sequential Chain\n",
        "\n",
        "Generate marketing content for promoting the system's features and benefits to potential clients. Marketing content, including both a product description and a website page, using the following sub-chains:\n",
        "\n",
        "Chain 1: Product Description Generation\n",
        "\n",
        "The first chain focuses on generating a compelling product description for the Team Tracking System. This description highlights key features and benefits that the system offers to managers and organizations.\n",
        "\n",
        "Chain 2: Website Page Description\n",
        "\n",
        "The second chain is responsible for crafting an engaging website page description that summarizes the product description and entices potential clients to learn more about the system. The description should be concise and attention-grabbing.\n",
        "\n",
        "We develop the Sequential Chain by connecting Chains 1 and 2 in the specified order.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tGHeMWsfOhHM"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Generate a compelling product description for the {product}? \\\n",
        "     Highlight key features and benefits.\"\n",
        ")\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aYYbvNnQOlXY"
      },
      "outputs": [],
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Craft an engaging website page description that summarizes the {product} description and entices potential clients to learn more about it.\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nZWBDLmlOzuv"
      },
      "outputs": [],
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "clAwTVSsO1k6",
        "outputId": "fe2a552f-a450-412f-ebd3-3e6515d4875c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mThe Team Tracking System is a powerful and user-friendly tool designed to help businesses manage their teams more effectively. With this system, you can easily keep track of your team members' progress, assign tasks, and monitor their performance, all in one convenient platform.\n",
            "\n",
            "One of the key features of the Team Tracking System is its real-time tracking capabilities. This means that you can see exactly what your team members are working on at any given moment, ensuring that everyone is on the same page and working towards the same goals.\n",
            "\n",
            "Another great feature of this system is its task management tools. With the Team Tracking System, you can assign tasks to specific team members, set deadlines, and track progress all in one place. This helps you stay organized and ensures that everyone is accountable for their part of the project.\n",
            "\n",
            "The benefits of using the Team Tracking System are numerous. First and foremost, it can help increase productivity and efficiency. By providing your team members with clear direction and regular feedback, you can ensure that everyone is working towards the same goals and making progress towards achieving them.\n",
            "\n",
            "Additionally, the Team Tracking System can improve communication and collaboration among team members. By having a central platform to share information and updates, everyone can stay informed and work together more seamlessly.\n",
            "\n",
            "Overall, the Team Tracking System is a powerful tool that can revolutionize the way you manage your teams. With its user-friendly interface, real-time tracking, and task management tools, you'll be able to streamline your processes and achieve better results in less time. Try it today and see the difference it can make for your business!\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mLooking to manage your team more effectively? The Team Tracking System is the perfect solution! With real-time tracking capabilities and a user-friendly interface, this tool makes it easy to assign tasks, monitor performance, and track progress all in one convenient platform. Increase productivity, improve collaboration, and streamline your processes with the Team Tracking System. Try it today and see the difference it can make for your business!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Looking to manage your team more effectively? The Team Tracking System is the perfect solution! With real-time tracking capabilities and a user-friendly interface, this tool makes it easy to assign tasks, monitor performance, and track progress all in one convenient platform. Increase productivity, improve collaboration, and streamline your processes with the Team Tracking System. Try it today and see the difference it can make for your business!'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "product = 'Team Tracking System'\n",
        "overall_simple_chain.run(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on9IuH_SQEPY"
      },
      "source": [
        "#### 3: Regular Sequential Chain for Team Tracking System\n",
        "\n",
        "Processing and analyzing a **project's status** using a Regular Sequential Chain using the following chains:\n",
        "\n",
        "Chain 1: Chain for Task Management\n",
        "\n",
        "This chain summarizes task status from the given input.\n",
        "\n",
        "Chain 2: Chain for Project Progress\n",
        "\n",
        "Based on the task statuses and summaries understand the overall project progress. It should provide information about project status, timelines, and updates.\n",
        "\n",
        "Chain 3: Chain for Team Performance\n",
        "\n",
        "Based on project progress give overall team performance, such as team productivity, performance metrics, etc.\n",
        "\n",
        "We combine these three chains into a Regular Sequential Chain.\n",
        "\n",
        "Displaying the following:\n",
        "1. Task Management\n",
        "2. Project Progress\n",
        "3. Team performance results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JaaToLCoPuhq"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
        "\n",
        "# prompt template 1: Task Management\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the status of the given:\"\n",
        "    \"\\n\\n{task}\"\n",
        ")\n",
        "# chain 1: input= task and output=task_summary\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"task_summary\"\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1JSvQbV1QdfK"
      },
      "outputs": [],
      "source": [
        "# prompt template 2: Project Progress\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Based on the {task_summary} understand the project progress. \\\n",
        "    It should provide information about project status, timelines, and updates.\"\n",
        ")\n",
        "# chain 2: input= task_summary and output=project_progress\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"project_progress\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xm4xHFo-QeDB"
      },
      "outputs": [],
      "source": [
        "# prompt template 3: Team Performance\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Give the overall team performance, such as team productivity, performance metrics, etc from the :\\n\\n{project_progress}\"\n",
        ")\n",
        "# chain 3: input= project_progress  and output=team_performance\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"team_performance\"\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WLrR9C8EQiSS"
      },
      "outputs": [],
      "source": [
        "# overall_chain: input= task\n",
        "# and output= task_summary,project_progress,team_performance\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three],\n",
        "    input_variables=[\"task\"],\n",
        "    output_variables=[\"task_summary\", \"project_progress\",\"team_performance\"],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u16pz1jLQmh3",
        "outputId": "6dc24844-0e84-4f3a-a818-7d5b6e6972df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'task': 'The Smart Office Implementation project aims to optimize workplace efficiency and sustainability through technology integration. Key tasks include Installation of IoT-based smart lighting and climate control systems. Deployment of occupancy sensors to monitor workspace utilization. Development of a mobile app for workspace customization. Integration of smart access controls for enhanced security. As of the latest update, the project is on schedule, with smart lighting and climate control systems operational. We anticipate significant energy savings and improved workspace utilization upon completion. The team remains committed to a smarter, more sustainable office environment.',\n",
              " 'task_summary': 'The Smart Office Implementation project aims to improve workplace efficiency and sustainability through technology integration. It includes installing smart lighting and climate control systems, deploying occupancy sensors, developing a mobile app for workspace customization, and integrating smart access controls for enhanced security. The project is on schedule, with smart lighting and climate control systems operational. The team expects significant energy savings and improved workspace utilization upon completion. They remain committed to creating a smarter, more sustainable office environment.',\n",
              " 'project_progress': 'The Smart Office Implementation project is currently underway and is on schedule. The project aims to improve workplace efficiency and sustainability through technology integration by installing smart lighting and climate control systems, deploying occupancy sensors, developing a mobile app for workspace customization, and integrating smart access controls for enhanced security. \\n\\nAs of now, the smart lighting and climate control systems have been installed and are operational. The team expects significant energy savings and improved workspace utilization upon completion of the project. \\n\\nThe project team remains committed to creating a smarter, more sustainable office environment, and they are actively working on the remaining tasks, including deploying occupancy sensors, developing the mobile app, and integrating smart access controls. \\n\\nOverall, the project progress is good, and the team is optimistic about achieving their goals. They will continue to provide updates on the project status and timelines as the work progresses.',\n",
              " 'team_performance': \"Based on the information provided, it is evident that the project team is performing well and is on track to successfully complete the Smart Office Implementation project. The team has already completed the installation of smart lighting and climate control systems, indicating high productivity levels.\\n\\nIn terms of performance metrics, the team expects to achieve significant energy savings and improved workspace utilization upon project completion. This indicates that the team has set measurable and achievable targets to evaluate the success of the project.\\n\\nFurthermore, the team's commitment to creating a smarter, more sustainable office environment demonstrates their dedication towards achieving project goals. This exemplifies good teamwork and collaboration amongst team members.\\n\\nIn conclusion, the overall team performance for the Smart Office Implementation project is commendable, and the team is optimistic about achieving their goals. As the project progresses, the team will continue to provide updates, and it is expected that the project will be completed within the expected timelines.\"}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "task = \"The Smart Office Implementation project aims to optimize workplace efficiency and sustainability through technology integration. Key tasks include \\\n",
        "Installation of IoT-based smart lighting and climate control systems. Deployment of occupancy sensors to monitor workspace utilization. \\\n",
        "Development of a mobile app for workspace customization. Integration of smart access controls for enhanced security. \\\n",
        "As of the latest update, the project is on schedule, with smart lighting and climate control systems operational. \\\n",
        "We anticipate significant energy savings and improved workspace utilization upon completion. The team remains committed to a smarter, more sustainable office environment.\"\n",
        "overall_chain(task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaajT3DrTo57"
      },
      "source": [
        "\n",
        "#### 4: Router Chain\n",
        "\n",
        "We create three separate LLM Chains, each specialized for handling specific types of inquiries related to the team tracking system:\n",
        "\n",
        "-- Employee attendance, Project Progress, and Inventory tracking.\n",
        "\n",
        "Defined prompts for each category.\n",
        "\n",
        "A Router Chain that routes manager inquiries to the appropriate subchain based on the content of the inquiry. The Router Chain has rules to identify keywords or phrases that indicate the inquiry category.\n",
        "\n",
        "Provided a list of sample manager inquiries related to task management, project progress, and team performance. Included inquiries that cover a range of scenarios and issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IergyAJJTjsj"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model=llm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UyPz49n8VyBw"
      },
      "outputs": [],
      "source": [
        "employee_attendance_template = \"\"\"You are the employee attendance manager. Your expertise lies in managing employee attendance records, tracking work hours, and addressing attendance-related inquiries. \\\n",
        "You can assist with attendance logging, leave approvals, and provide reports on employees' attendance history.\n",
        "\n",
        "Here is an employee attendance inquiry:\n",
        "{input}\n",
        "\"\"\"\n",
        "\n",
        "project_progress_template = \"\"\"You are the project progress coordinator. Your role is to monitor and report on the progress of ongoing projects. \\\n",
        "You can provide updates on project timelines, milestones, and potential risks.\n",
        "\n",
        "Here is a project progress inquiry:\n",
        "{input}\n",
        "\"\"\"\n",
        "\n",
        "inventory_tracking_template = \"\"\"You are the inventory tracking specialist. You excel in managing inventory records and tracking stock levels. \\\n",
        "You can assist with inquiries related to product availability, stock updates, and inventory reports.\n",
        "\n",
        "Here is an inventory tracking inquiry:\n",
        "{input}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TS0R7UuTW4KA"
      },
      "outputs": [],
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"employee attendance\",\n",
        "        \"description\": \"To assist in employee attendance inquiries\",\n",
        "        \"prompt_template\": employee_attendance_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"project progress\",\n",
        "        \"description\": \"To assist in project progress inquiries\",\n",
        "        \"prompt_template\": project_progress_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"inventory tracking\",\n",
        "        \"description\": \"To assist in inventory tracking inquiries\",\n",
        "        \"prompt_template\": inventory_tracking_template\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "m_R0lekSXQbO"
      },
      "outputs": [],
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7W4bdUK8XWie"
      },
      "outputs": [],
      "source": [
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "88699ANwXauh"
      },
      "outputs": [],
      "source": [
        "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
        "language model select the model prompt best suited for the input. \\\n",
        "You will be given the names of the available prompts and a \\\n",
        "description of what the prompt is best suited for. \\\n",
        "You may also revise the original input if you think that revising\\\n",
        "it will ultimately lead to a better response from the language model.\n",
        "\n",
        "<< FORMATTING >>\n",
        "Return a markdown code snippet with a JSON object formatted to look like:\n",
        "```json\n",
        "{{{{\n",
        "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
        "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
        "}}}}\n",
        "```\n",
        "\n",
        "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
        "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
        "well suited for any of the candidate prompts.\n",
        "REMEMBER: \"next_inputs\" can just be the original input \\\n",
        "if you don't think any modifications are needed.\n",
        "\n",
        "<< CANDIDATE PROMPTS >>\n",
        "{destinations}\n",
        "\n",
        "<< INPUT >>\n",
        "{{input}}\n",
        "\n",
        "<< OUTPUT (remember to include the ```json)>>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WDybteuBXis8"
      },
      "outputs": [],
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1ltbGaY3XnL0"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(router_chain=router_chain,\n",
        "                         destination_chains=destination_chains,\n",
        "                         default_chain=default_chain, verbose=True\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5PHzeiQ8XrHt"
      },
      "outputs": [],
      "source": [
        "employee_attendance_inquiries = [\"Can you provide a report on the overall team's attendance for the past quarter?\",\n",
        "\"What's the average employee attendance rate for our department this month?\",\n",
        "\"I need to approve a leave request for John Smith. Can you confirm his available leave balance?\",\n",
        "\"What's our policy regarding remote work attendance tracking?\"]\n",
        "\n",
        "project_progress_inquiries = [\"Are there any outstanding issues affecting the 'Market Expansion' project's timeline?\",\n",
        "\"What's the budget utilization status for the 'Client Onboarding' project?\",\n",
        "\"Provide a summary of the 'Quality Assurance' project's progress and any potential bottlenecks.\",\n",
        "\"We need a forecast for the 'Annual Sales Report' project completion date.\"]\n",
        "\n",
        "inventory_tracking_inquiries = [\"We're planning a promotional campaign. Can you confirm if we have enough product XYZ in stock?\",\n",
        "\"Can you provide an inventory report showing the levels of raw materials for production?\",\n",
        "\"What's our restocking strategy for office supplies, and how frequently do we reorder?\",\n",
        "\"I need a report on the inventory turnover rates for each product category.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "GbunnfCUYxCb",
        "outputId": "720ff9d4-3ef5-461d-d58b-404fac4eb704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "employee attendance: {'input': \"Can you provide a report on the overall team's attendance for the past quarter?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Yes, I can definitely provide a report on the overall team's attendance for the past quarter. I will need to access our attendance tracking system to gather the necessary data. Once I have compiled the information, I can generate a report that includes attendance rates, absences, tardiness, and any other relevant attendance-related data. Please let me know if there are any specific details you would like me to include in the report.\""
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(employee_attendance_inquiries[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "VX6eVsieYzNN",
        "outputId": "ccc6ce49-f3e3-4927-e521-d19b0c434e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "employee attendance: {'input': \"What's the average employee attendance rate for our department this month?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thank you for your inquiry. I can provide you with the average employee attendance rate for your department this month. May I know the name of your department and the specific dates you would like me to pull the attendance records for? This will help me provide you with accurate information.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(employee_attendance_inquiries[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "WJ2-D3K0Y0_X",
        "outputId": "a05e7eb3-6008-4682-d07e-f14e8364c915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "employee attendance: {'input': \"Can you provide me with John Smith's employee ID number?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"As the employee attendance manager, I can assist you with attendance-related inquiries, but I do not have access to employee ID numbers. Please reach out to the HR department or John Smith's supervisor for assistance with obtaining his employee ID number.\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(employee_attendance_inquiries[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "jF3SxFyVY2yQ",
        "outputId": "8646694d-f567-4fd9-cdbc-2f522f88786b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "project progress: {'input': \"Are there any outstanding issues affecting the 'Market Expansion' project's timeline?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"As the project progress coordinator, I can confirm that there are currently no outstanding issues affecting the timeline of the 'Market Expansion' project. The project is progressing as planned and all milestones are being met on schedule. However, we will continue to monitor the project closely and will promptly address any potential risks that may arise.\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(project_progress_inquiries[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "LjHQXo9fY6Zv",
        "outputId": "d092d899-a185-47f7-95f7-0a5b753fc8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "project progress: {'input': \"What's the budget utilization status for the 'Client Onboarding' project?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"As the project progress coordinator, I can provide the following update on the budget utilization status for the 'Client Onboarding' project:\\n\\nCurrently, the project is within the allocated budget. However, we are closely monitoring the expenses and ensuring that we stay within the budget throughout the project's duration. We have implemented cost-saving measures where possible and are regularly reviewing the budget to identify any potential risks or areas where we can optimize spending. Overall, we are confident that we will successfully complete the project within the allocated budget.\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(project_progress_inquiries[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "u_WQXqQVY7fA",
        "outputId": "b49f583a-8e54-4096-c547-e68a7480251c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "project progress: {'input': \"Please provide an update on the progress of the 'Quality Assurance' project and identify any potential bottlenecks.\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Thank you for your inquiry. As the project progress coordinator, I am happy to provide an update on the 'Quality Assurance' project.\\n\\nCurrently, the project is progressing according to the established timeline. The team has completed the initial planning phase and is now in the execution phase. The team has successfully identified the quality standards and requirements for the project and has developed a comprehensive quality assurance plan.\\n\\nHowever, there are a few potential bottlenecks that we have identified. One of the main challenges is the availability of resources, particularly in terms of personnel. The team is currently working with limited resources, which may impact the project's progress in the coming weeks.\\n\\nAdditionally, there may be potential risks associated with the implementation of the quality assurance plan. The team is working to mitigate these risks by conducting regular reviews and assessments of the plan.\\n\\nOverall, we are confident that the 'Quality Assurance' project will be completed successfully, but we will continue to monitor progress and address any potential bottlenecks as they arise.\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(project_progress_inquiries[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1b78RGJhY8YM",
        "outputId": "3a138352-961d-47b4-a32f-31d6216c1a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "inventory tracking: {'input': \"We're planning a promotional campaign. Can you confirm if we have enough product XYZ in stock?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Certainly! I can check our inventory records to see if we have enough product XYZ in stock. May I have the product code or SKU number for XYZ?'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(inventory_tracking_inquiries[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "5CtRa8n4ZAVo",
        "outputId": "045b3db2-c5c7-4bde-f1e9-6d97b5fd470d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "inventory tracking: {'input': 'Can you provide an inventory report showing the levels of raw materials for production?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Certainly! I can generate an inventory report that shows the current levels of all raw materials used in production. This report will include the quantity on hand, any pending orders, and any upcoming deliveries. Would you like me to send this report to you via email or provide it in a physical copy?'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(inventory_tracking_inquiries[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "t0H2zf6eZBAZ",
        "outputId": "10c3c3a8-dd9b-4ae9-9b0d-cb0d643b7466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "inventory tracking: {'input': 'What is our current inventory level for office supplies and when was the last time we placed an order?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'As the inventory tracking specialist, I can provide you with the current inventory level for office supplies and the date of the last order. However, I would need access to our inventory management system to retrieve this information. Please provide me with the necessary login credentials or access to the system, and I will be happy to assist you with your inquiry.'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(inventory_tracking_inquiries[2])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
