{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. LLM Chain (Large Language Model Chain)\n",
        "\n",
        "We'll create an LLM Chain using Large Language Models (LLMs) to generate three different types of content: a story title, a poem, and a joke.\n",
        "\n",
        "For each content type, we define a specific prompt that the LLM Chain will use.\n",
        "Let's run the LLM Chain with each of the three prompts and display the generated content."
      ],
      "metadata": {
        "id": "Q2UVgXJB3Sjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from secret_key import openai_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openai_key"
      ],
      "metadata": {
        "id": "4RMqFc1VU704"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install langchain\n",
        "!pip3 install openai=='0.28.1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9236Lr23Usw",
        "outputId": "7fea11af-b0c6-4621-bfab-689b1d78a292"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Mc9PBp1j36oU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "X8V7HWVOU2KL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# account for deprecation of LLM model\n",
        "import datetime\n",
        "# Get the current date\n",
        "current_date = datetime.datetime.now().date()\n",
        "\n",
        "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
        "target_date = datetime.date(2024, 6, 12)\n",
        "\n",
        "# Set the model variable based on the current date\n",
        "if current_date > target_date:\n",
        "    llm_model = \"gpt-3.5-turbo\"\n",
        "else:\n",
        "    llm_model = \"gpt-3.5-turbo-0301\""
      ],
      "metadata": {
        "id": "70UH-WD7VGS8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade openai"
      ],
      "metadata": {
        "id": "5TrZo13YVQ8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
      ],
      "metadata": {
        "id": "8QUaCUrlVKk4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A story title"
      ],
      "metadata": {
        "id": "idTg0qmqcBh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to give to \\\n",
        "    the title of this {story}?\"\n",
        ")"
      ],
      "metadata": {
        "id": "uLihlG3ocIDS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "haTd_t88cdOf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"After flying a long distance, a thirsty crow was wandering the forest in search of water. Finally, he saw a pot half-filled with water. He tried to drink from it but his beak wasn’t long enough to reach the water inside. \\\n",
        "He then saw pebbles on the ground and one by one, he put them in the pot until the water rose to the brim. The crow then hastily drank from it and quenched his thirst.\"\n",
        "chain.run(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-k0lu-Rdceni",
        "outputId": "29711ffa-3941-4257-b319-19089c4e44d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"The Clever Crow and the Pot of Water\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poem"
      ],
      "metadata": {
        "id": "z5INrtRZcETx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Compose a 15 line heartfelt poem that captures the struggles of {input}\"\n",
        ")"
      ],
      "metadata": {
        "id": "3OyrI56KdAwg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "Xi3e69MQfVrv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"mother whose son has gone to war\"\n",
        "chain.run(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "EkUtbf_ue3VZ",
        "outputId": "898f8284-ed03-461b-9b03-a0c6a2b8443b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A mother's heart is heavy and torn,\\nHer son has left for war to be borne,\\nHer days are filled with worry and fear,\\nHoping that her son is still near.\\n\\nShe prays for his safety every night,\\nWith all her might and all her sight,\\nHer thoughts are consumed with his fate,\\nWondering if he's safe and sound or late.\\n\\nShe dreams of his homecoming with glee,\\nHoping one day he'll again be free,\\nHer heart rejoices with every letter,\\nKnowing that her son is still better.\\n\\nShe waits for the day he comes back,\\nHer love for him will never slack,\\nFor a mother's love is forever and true,\\nHer son's safety is all she wants anew.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joke"
      ],
      "metadata": {
        "id": "WMeTw7izcGd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a short funny, non-racist, unbiased, non-sexist joke about {input}\"\n",
        ")"
      ],
      "metadata": {
        "id": "0A-5xcHfWwDE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "YjqgaMdHfu2H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"women\"\n",
        "chain.run(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yPRjwxLbfwrV",
        "outputId": "3e9ef452-2bbf-4c17-bc0a-aa024e9f5398"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the woman take a ladder to the bar? \\n\\nBecause she heard the drinks were on the house!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2: Sequential Chain\n",
        "\n",
        "We now create two separate LLM Chains: one for generating a product description and another for crafting a social media post.\n",
        "Combine these two chains into a **Sequential Chain**.\n",
        "Provide a product description prompt and a social media post prompt.\n",
        "\n",
        "We run the Sequential Chain with the prompts and display the generated marketing content."
      ],
      "metadata": {
        "id": "OAxdo_ExgVuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "TkTezQWSgW_V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you please provide a detailed technical product description for {product}\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
      ],
      "metadata": {
        "id": "6NZtkKVAhkel"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Create an engaging and catchy social media post to promote the launch of our upcoming {product}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "3b3qe-lehqGb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ],
      "metadata": {
        "id": "v4D628e4hsQO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product = \"laptop\"\n",
        "overall_simple_chain.run(product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "-XXBDUhPhu8q",
        "outputId": "1310d423-b91f-4e78-d0fa-430bc199364b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mAs an AI language model, I can provide you with a generic technical product description for laptops.\n",
            "\n",
            "A laptop is a portable computer that is designed to be used on-the-go. It typically features a compact and lightweight design, a built-in screen, keyboard, and touchpad. It can be powered by battery or plugged into an electrical outlet for charging. Laptops generally run on an operating system such as Windows, macOS, or Linux.\n",
            "\n",
            "Laptops may vary in their specifications, depending on their intended use and price range. However, most laptops will feature a central processing unit (CPU), which acts as the computer's brain. The CPU will usually be manufactured by companies such as Intel or AMD and will have a specified clock speed, measured in GHz.\n",
            "\n",
            "Laptops will also have a certain amount of random access memory (RAM), which acts as a short-term memory for the computer. The amount of RAM will vary by laptop but typically ranges from 4GB to 16GB or more.\n",
            "\n",
            "Laptops have a hard disk drive (HDD) or a solid-state drive (SSD), which serves as a permanent memory storage for all files and applications on the computer. The amount of storage will vary by laptop and can range from 256GB to 2TB or more.\n",
            "\n",
            "Laptops also come equipped with various ports and connectivity options such as USB, HDMI, Thunderbolt, Wi-Fi, Bluetooth, and Ethernet. These ports allow the laptop to connect to peripherals such as external hard drives, displays, and printers.\n",
            "\n",
            "Finally, laptops also come with a variety of software applications pre-installed or can be downloaded from the internet. These include productivity software such as Microsoft Office, web browsers, and multimedia applications.\n",
            "\n",
            "Overall, a laptop is an essential tool for people who are frequently on-the-go and require a portable computer to complete their work or entertainment needs.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mAre you in need of a portable computer to tackle your work or entertainment needs? Look no further than our upcoming laptop launch! Our top-of-the-line laptops come equipped with everything you need for your on-the-go lifestyle, including a speedy CPU, ample RAM and storage, a variety of ports, and pre-installed software. Stay tuned for more information on our highly anticipated launch! #laptoplaunch #portablepower #ontheGocomputing\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Are you in need of a portable computer to tackle your work or entertainment needs? Look no further than our upcoming laptop launch! Our top-of-the-line laptops come equipped with everything you need for your on-the-go lifestyle, including a speedy CPU, ample RAM and storage, a variety of ports, and pre-installed software. Stay tuned for more information on our highly anticipated launch! #laptoplaunch #portablepower #ontheGocomputing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Regular Sequential Chain\n",
        "\n",
        "To see an exampe of a Regular Sequential Chain, we will do the following:\n",
        "1. Choose a text in a non-English language of your choice.\n",
        "2. Create three separate chains for the following tasks:\n",
        "\n",
        "- Chain 1: Language translation from the chosen language to English.\n",
        "\n",
        "- Chain 2: Summarization of the translated text (maximum 100 words).\n",
        "\n",
        "- Chain 3: Sentiment analysis of the summarized text.\n",
        "\n",
        "3. Combine these three chains into a Regular Sequential Chain.\n",
        "4. Run the Regular Sequential Chain with the provided text and display the following:\n",
        "\n",
        "-  Translated text.\n",
        "\n",
        "- Text summary.\n",
        "\n",
        "-  Sentiment analysis results."
      ],
      "metadata": {
        "id": "7mNKkbJ6j-JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "KvWdmc18iL8y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
        "\n",
        "# prompt template 1: translate to english\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following text to english:\"\n",
        "    \"\\n\\n{Non-English_text}\"\n",
        ")\n",
        "# chain 1: input= Non-English text and output=translated_text\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"translated_text\"\n",
        "                    )\n"
      ],
      "metadata": {
        "id": "0QIRtniWlEve"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2: summarize translated text\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you summarize the following translated text using maximum 100 words:\"\n",
        "    \"\\n\\n{translated_text}\"\n",
        ")\n",
        "# chain 2: input= translated_text and output=summary\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"summary\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "3QAViDeHlJ0a"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: sentiment analysis of translated text\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you provide a sentiment analysis for this :\\n\\n{summary}\"\n",
        ")\n",
        "# chain 3: input= summary  and output= sentiment_analysis\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"sentiment_analysis\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "9jGpqviulMGm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_chain: input= Non-English_text\n",
        "# and output= translated_text,summary,sentiment_analysis\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three],\n",
        "    input_variables=[\"Non-English_text\"],\n",
        "    output_variables=[\"translated_text\", \"summary\",\"sentiment_analysis\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "RgUvVgarlR0y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"भारत दक्षिण एशिया में स्थित भारतीय उपमहाद्वीप का सबसे बड़ा देश है। भारत भौगोलिक दृष्टि से विश्व का सातवाँ सबसे बड़ा देश है, जबकि जनसंख्या के दृष्टिकोण से चीन के बाद दूसरा सबसे बड़ा देश है। भारत के पश्चिम में पाकिस्तान, उत्तर-पूर्व में चीन (तिब्बत), नेपाल और भूटान, पूर्व में बांग्लादेश और म्यान्मार स्थित हैं। भारतीय महासागर में इसके दक्षिण पश्चिम में मालदीव, दक्षिण में श्रीलंका और दक्षिण-पूर्व में इंडोनेशिया से भारत की सामुद्रिक सीमा लगती है। इसके उत्तर में हिमालय पर्वत तथा दक्षिण में भारतीय महासागर स्थित है। दक्षिण-पूर्व में बंगाल की खाड़ी तथा पश्चिम में अरब सागर है।\"\n",
        "overall_chain(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp1GqPVBlUg6",
        "outputId": "389fd8cd-2a6b-4608-cb41-2a3fb0c05cca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Non-English_text': 'भारत दक्षिण एशिया में स्थित भारतीय उपमहाद्वीप का सबसे बड़ा देश है। भारत भौगोलिक दृष्टि से विश्व का सातवाँ सबसे बड़ा देश है, जबकि जनसंख्या के दृष्टिकोण से चीन के बाद दूसरा सबसे बड़ा देश है। भारत के पश्चिम में पाकिस्तान, उत्तर-पूर्व में चीन (तिब्बत), नेपाल और भूटान, पूर्व में बांग्लादेश और म्यान्मार स्थित हैं। भारतीय महासागर में इसके दक्षिण पश्चिम में मालदीव, दक्षिण में श्रीलंका और दक्षिण-पूर्व में इंडोनेशिया से भारत की सामुद्रिक सीमा लगती है। इसके उत्तर में हिमालय पर्वत तथा दक्षिण में भारतीय महासागर स्थित है। दक्षिण-पूर्व में बंगाल की खाड़ी तथा पश्चिम में अरब सागर है।',\n",
              " 'translated_text': 'India is the largest country in the Indian subcontinent located in South Asia. Geographically, India is the seventh largest country in the world, while in terms of population, it is the second largest country after China. Pakistan is located to the west of India, China (Tibet), Nepal and Bhutan are located to the north-east, and Bangladesh and Myanmar are located to the east. In the Indian Ocean, the Maldives are located to the south-west of India, Sri Lanka to the south, and Indonesia to the south-east. The Himalayan mountains are located to the north, and the Indian Ocean to the south. The Bay of Bengal is located to the south-east, and the Arabian Sea to the west.',\n",
              " 'summary': 'India, located in South Asia, is the largest country in the Indian subcontinent, 7th largest in the world, and 2nd most populous after China. It is bordered by Pakistan, China, Nepal, Bhutan, Bangladesh, Myanmar, the Maldives, Sri Lanka, and Indonesia. The Himalayan mountains are to the north, Indian Ocean to the south, Bay of Bengal to the southeast, and Arabian Sea to the west.',\n",
              " 'sentiment_analysis': 'As an AI language model, I am not capable of having sentiment as humans do. However, this text appears to be neutral and informative, providing factual information about the geography and demographics of India without expressing any particular positive or negative emotions.'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Router Chain (Combining All Concepts)\n",
        "\n",
        "Now, let's combine all the concepts we have seen so far with the help of a use-case.\n",
        "\n",
        "Use case: Customer support for a travel booking platform\n",
        "\n",
        "Imagine you are developing a customer support system for a travel booking platform. The platform provides services related to flight bookings, hotel reservations, and car rentals. Our task is to create a Router Chain that routes customer inquiries to the appropriate sub chains based on the nature of the inquiry.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Create three separate LLM Chains, each specialized for handling specific types of customer inquiries related to the travel booking platform: Flight Booking, Hotel Reservation, and Car Rental. We will define prompts for each category.\n",
        "\n",
        "2. Create a Router Chain that routes customer inquiries to the appropriate subchain based on the content of the inquiry. The Router Chain will have rules to identify keywords or phrases that indicate the inquiry category.\n",
        "\n",
        "3. Provide a list of sample customer inquiries related to flight bookings, hotel reservations, and car rentals. We will include inquiries that cover a range of scenarios and issues.\n",
        "\n",
        "4. Run the Router Chain with the sample inquiries and display the responses for each category. We will ensure that inquiries are routed correctly to the relevant subchains."
      ],
      "metadata": {
        "id": "84rcpcOGo6aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "_ElRdW2nogjE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model=llm_model)"
      ],
      "metadata": {
        "id": "OAmQbaEJx83t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flight_booking_template = \"\"\"You are the flight booking expert. \\\n",
        "You specialize in helping customers with flight-related inquiries. \\\n",
        "You can assist with finding flights, booking tickets, and providing information \\\n",
        "on airlines, routes, and schedules.\n",
        "\n",
        "Here is a flight-related inquiry:\n",
        "{input}\"\"\"\n",
        "\n",
        "hotel_reservation_template = \"\"\"You are the hotel reservation specialist. \\\n",
        "You excel at handling hotel-related inquiries. You can assist with hotel bookings, \\\n",
        "room availability, amenities, and provide details on various lodging options.\n",
        "\n",
        "Here is a hotel reservation inquiry:\n",
        "{input}\"\"\"\n",
        "\n",
        "car_rental_template = \"\"\"You are the car rental expert. \\\n",
        "You specialize in helping customers with car rental inquiries. \\\n",
        "You can provide information on available vehicles, rates, features, and help customers \\\n",
        "find the perfect rental car for their needs.\n",
        "\n",
        "Here is a car rental inquiry:\n",
        "{input}\"\"\""
      ],
      "metadata": {
        "id": "rryCRPRkylM5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"flight booking\",\n",
        "        \"description\": \"To assist in flight booking inquiries\",\n",
        "        \"prompt_template\": flight_booking_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"hotel reservation\",\n",
        "        \"description\": \"To assist in hotel reservation inquiries\",\n",
        "        \"prompt_template\": hotel_reservation_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"car rental\",\n",
        "        \"description\": \"To assist in car rental inquiries\",\n",
        "        \"prompt_template\": car_rental_template\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "PV1Rx3Lnyn_I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)"
      ],
      "metadata": {
        "id": "1B5xtjSAx_3d"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
      ],
      "metadata": {
        "id": "vrKJs8hyyovm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
        "language model select the model prompt best suited for the input. \\\n",
        "You will be given the names of the available prompts and a \\\n",
        "description of what the prompt is best suited for. \\\n",
        "You may also revise the original input if you think that revising\\\n",
        "it will ultimately lead to a better response from the language model.\n",
        "\n",
        "<< FORMATTING >>\n",
        "Return a markdown code snippet with a JSON object formatted to look like:\n",
        "```json\n",
        "{{{{\n",
        "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
        "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
        "}}}}\n",
        "```\n",
        "\n",
        "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
        "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
        "well suited for any of the candidate prompts.\n",
        "REMEMBER: \"next_inputs\" can just be the original input \\\n",
        "if you don't think any modifications are needed.\n",
        "\n",
        "<< CANDIDATE PROMPTS >>\n",
        "{destinations}\n",
        "\n",
        "<< INPUT >>\n",
        "{{input}}\n",
        "\n",
        "<< OUTPUT (remember to include the ```json)>>\"\"\""
      ],
      "metadata": {
        "id": "pjV8fjNgyrh5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ],
      "metadata": {
        "id": "i0dpbLGWyucf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = MultiPromptChain(router_chain=router_chain,\n",
        "                         destination_chains=destination_chains,\n",
        "                         default_chain=default_chain, verbose=True\n",
        "                        )"
      ],
      "metadata": {
        "id": "6cSAJcjcywR_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### A list of sample customer inquiries related to flight bookings, hotel reservations, and car rentals."
      ],
      "metadata": {
        "id": "jocnMgpG3MJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flight_booking_inquiries = [\"I need to book a one-way flight from New York to London for next week. Can you help?\",\n",
        "\"What are the best deals on round-trip flights to Paris in July?\",\n",
        "\"I missed my connecting flight. Can you assist me with rebooking?\",\n",
        "\"I want to upgrade my economy class ticket to business class for my upcoming flight.\"]\n",
        "\n",
        "hotel_reservation_inquiries = [\"I'm looking for a family-friendly hotel in Orlando with a pool for a week-long stay.\",\n",
        "\"What's the availability of beachfront hotels in Miami for the weekend?\",\n",
        "\"Do you have any pet-friendly hotels in San Francisco for my dog?\",\n",
        "\"I need to cancel my hotel reservation due to a change in my travel plans.\"]\n",
        "\n",
        "car_rental_inquiries = [\n",
        "\"I'm interested in renting a compact car for a week in Los Angeles. What's the rate?\",\n",
        "\"Do you have any luxury SUVs available for rent in Las Vegas?\",\n",
        "\"I want to extend my car rental for a few more days. Can you help with that?\",\n",
        "\"Are there any special deals on long-term car rentals for a cross-country road trip?\"]"
      ],
      "metadata": {
        "id": "RouKP-gM2c3Z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  Running the Router Chain with the sample inquiries and displaying the responses for each category."
      ],
      "metadata": {
        "id": "c9NlOCxY3SmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(flight_booking_inquiries[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "HM4DZ5jCyyK-",
        "outputId": "a33c5fe7-f289-4e59-cbed-21fc4c7c6389"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "flight booking: {'input': 'I need to book a one-way flight from New York to London for next week. Can you help?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Absolutely! I'd be happy to assist you with booking a one-way flight from New York to London for next week. Can you please provide me with your preferred travel dates and any specific airline preferences you may have? Additionally, do you have any flexibility with your travel dates or are they set in stone?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(flight_booking_inquiries[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "NdlUQHHDyzst",
        "outputId": "cbcbae82-722b-4174-c4f6-7580ddcc3156"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "flight booking: {'input': 'What are the best deals on round-trip flights to Paris in July?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Certainly! I can help you find the best deals on round-trip flights to Paris in July. Can you please provide me with your departure city and preferred travel dates? This will help me narrow down the search and provide you with the most accurate information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(flight_booking_inquiries[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "RjEmMpMN3aTH",
        "outputId": "9f4aea43-776a-495e-878d-da8cc6c94815"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "flight booking: {'input': 'I need help rebooking my missed connecting flight.'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry to hear that you missed your connecting flight. I can definitely assist you with rebooking your flight. Can you please provide me with your booking reference number and the airline you were traveling with? This will help me to quickly access your booking and provide you with the available options for rebooking. Additionally, please let me know your preferred travel dates and times so that I can check for availability and provide you with the best possible options.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(hotel_reservation_inquiries[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "jNLmqe0j3bxy",
        "outputId": "707dcbea-cb27-47a4-b63e-096c9e09731c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "hotel reservation: {'input': \"I'm looking for a family-friendly hotel in Orlando with a pool for a week-long stay.\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thank you for your inquiry! We have several family-friendly hotels in Orlando that offer great amenities, including pools. Can you please provide me with your preferred dates of stay so I can check availability for you? Additionally, do you have any specific location or budget preferences? This will help me narrow down the options and provide you with the best possible recommendations. Thank you!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(hotel_reservation_inquiries[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "RpgaRmnT3nxY",
        "outputId": "bd0db190-824e-48e7-c65a-00dd1ff69184"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "hotel reservation: {'input': \"What's the availability of beachfront hotels in Miami for the weekend?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thank you for your inquiry. I would be happy to assist you with finding beachfront hotels in Miami for the weekend. Can you please provide me with the specific dates you are looking to stay? This will help me to check availability and provide you with the best options. Thank you.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(hotel_reservation_inquiries[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "8o6fvT8_3qC1",
        "outputId": "123f40d2-7b4b-43fb-d411-f36d6f7c3da0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "hotel reservation: {'input': 'Do you have any pet-friendly hotels in San Francisco for my dog?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, we do have pet-friendly hotels in San Francisco. Some of our top recommendations include Hotel Nikko San Francisco, The Westin St. Francis San Francisco on Union Square, and The Kimpton Buchanan. Each of these hotels offers pet-friendly accommodations and amenities for your furry friend. Would you like me to check availability and rates for your desired dates?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(car_rental_inquiries[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "dN-q2ZpJ3xrR",
        "outputId": "62c6b27e-558a-48c1-ede6-1244d8d84f4a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "car rental: {'input': \"I'm interested in renting a compact car for a week in Los Angeles. What's the rate?\"}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Great! We have several options for compact cars available for rent in Los Angeles. The rate for a compact car rental for a week in Los Angeles starts at $35 per day. However, the final rate may vary depending on the specific vehicle you choose, any additional features you may want, and any applicable taxes and fees. Would you like me to check availability and provide you with a more accurate quote?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(car_rental_inquiries[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "HCtEtR7237N6",
        "outputId": "a0ed4238-439a-43f4-8865-ad62680a8414"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "car rental: {'input': 'Do you have any luxury SUVs available for rent in Las Vegas?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, we do have luxury SUVs available for rent in Las Vegas. Our fleet includes a variety of luxury SUVs from top brands such as BMW, Mercedes-Benz, and Audi. These vehicles come equipped with premium features such as leather seats, advanced entertainment systems, and state-of-the-art safety features. Please let me know your preferred rental dates and I can provide you with a quote and help you reserve the perfect luxury SUV for your needs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(car_rental_inquiries[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "2mvIZZoU39AG",
        "outputId": "f0756865-e96e-4bc2-cd73-995c007cd731"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "car rental: {'input': 'I want to extend my car rental for a few more days. Can you help with that?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Absolutely! I can definitely assist you with extending your car rental. May I have your reservation number and the date you would like to extend your rental until? This will allow me to check availability and provide you with the updated rental rate.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Custom Chain\n",
        "\n",
        "We create a custom chain and outline the steps involved in our chain.\n",
        "\n",
        "I have provided examples of input data and expected output."
      ],
      "metadata": {
        "id": "yyKtz_jD4PRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of my use-case"
      ],
      "metadata": {
        "id": "DVKS9cCY-HbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are developing a multi-stage data processing system for analyzing movie reviews. The system is composed of the following chains:\n",
        "\n",
        "Chain 1: Text Translation\n",
        "\n",
        "Translate text about movie reviews from given non-english language.\n",
        "\n",
        "Chain 2: Text Summarization\n",
        "\n",
        "Summarize the given movie review\n",
        "\n",
        "Chain 3: Sentiment Analysis\n",
        "\n",
        "Provide sentiment analysis of the movie review. Is it a positive, negative or a neutral movie review?\n",
        "\n",
        "Chain 4: Categorize the main topics or themes\n",
        "\n",
        "Use the translated text to identify the main theme of the movie review\n",
        "\n",
        "Chain 5: Identify reason for the sentiment from given summarized movie review and theme\n",
        "\n",
        "Use the main topics and movie summary to understand why we got a particular sentiment\n",
        "\n",
        "I find this use-case interesting as it involves multiple NLP tasks and data processing stages to analyze movie reviews comprehensively. What makes it fascinating is the ability to extract valuable insights from text data, not only by translating and summarizing it but also by determining sentiment, categorizing topics, and understanding the reasons behind the sentiment.\n",
        "\n",
        "EXAMPLES\n",
        "\n",
        "Input Data:\n",
        "Movie Review (Non-English Language): \"El último film que vi fue increíble. La trama y los personajes son emocionantes.\"\n",
        "\n",
        "Expected Output:\n",
        "\n",
        "Translated Movie Review (English): \"The last movie I watched was incredible. The plot and characters are thrilling.\"\n",
        "\n",
        "Movie Review Summary: \"Incredible movie with an exciting plot and characters.\"\n",
        "\n",
        "Sentiment Analysis: Positive\n",
        "\n",
        "Main Topics: \"Movie, Plot, Characters\"\n",
        "\n",
        "Reasons for the Positive Sentiment: \"Exciting plot and characters\"\n",
        "\n",
        "This can be expanded to other movie reviews as well as will be seen below."
      ],
      "metadata": {
        "id": "6_ifXGTm-KdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "Zj3PiXre-J3_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
        "\n",
        "# prompt template 1: translate review to english\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following text to english:\"\n",
        "    \"\\n\\n{Non-English_text}\"\n",
        ")\n",
        "# chain 1: input= Non-English text and output=translated_text\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"translated_text\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "CbPx03nL4Qir"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2: summarize translated movie\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you summarize the following translated text using maximum 100 words:\"\n",
        "    \"\\n\\n{translated_text}\"\n",
        ")\n",
        "# chain 2: input= translated_text and output=summary\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"summary\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "tK2XBaavBh6N"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: sentiment analysis of translated moview review\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you provide a sentiment analysis for this :\\n\\n{translated_text}\"\n",
        ")\n",
        "# chain 3: input= translated_text  and output= sentiment_analysis\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"sentiment_analysis\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "LbXF8249Bkf0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 4: identify movie review theme\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you idenitfy the main topic or theme in this movie review:\\n\\n{translated_text}\"\n",
        ")\n",
        "# chain 4: input= translated_text  and output= movie theme\n",
        "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
        "                       output_key=\"movie_theme\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "ikYUhgVSCS0a"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 5: reason for given sentiment\n",
        "fifth_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Use the main topics: {movie_theme} and movie summary:{summary} to understand Why we got a particular sentiment:\\n\\n{sentiment_analysis}\"\n",
        ")\n",
        "# chain 5: input= translated_text  and output= movie theme\n",
        "chain_five = LLMChain(llm=llm, prompt=fifth_prompt,\n",
        "                       output_key=\"reason\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "YBRP8-DJDOp_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_chain: input= Non-English_text\n",
        "# and output= translated_text, summary, sentiment_analysis, movie_theme, reason\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four, chain_five],\n",
        "    input_variables=[\"Non-English_text\"],\n",
        "    output_variables=[\"translated_text\", \"summary\",\"sentiment_analysis\",\"movie_theme\",\"reason\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "hLbDLDcXBnd5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"कोविड-19 का प्रकोप मानव इतिहास में हमेशा एक काला अध्याय रहेगा। हममें से कई लोगों ने अपने किसी प्रियजन या किसी जानने वाले को खो दिया है और हमने पहले कभी इतना असहाय महसूस नहीं किया। \\\n",
        "यह फिल्म विशेष रूप से उन लोगों के लिए प्रेरक हो सकती है जिन्हें महामारी के दौरान व्यक्तिगत क्षति का सामना करना पड़ा।कहानी कोवैक्सिन के चरण-दर-चरण निर्माण का अनुसरण करती है जिसे भारत बायोटेक द्वारा आईसीएमआर और नेशनल इंस्टीट्यूट ऑफ वायरोलॉजी (एनआईवी) के सहयोग से विकसित किया गया था। 2 घंटे, 40 मिनट की कठिन अवधि के दौरान, मेडिकल ड्रामा उन घटनाओं को फिर से दिखाता है जो चीन के वुहान में कोरोनोवायरस के प्रकोप के बाद भारत में सामने आईं। \\\n",
        "यह एक उपदेशात्मक खंडन के रूप में भी काम करता है, जो बड़ी संख्या में मानव जीवन लेने वाली महामारी से कथित तौर पर खराब तरीके से निपटने के लिए केंद्र सरकार की भारी आलोचना का सामना करता है। 'द वैक्सीन वॉर' को दो कहानियों में बांटा जा सकता है। पहले भाग में वैज्ञानिकों के जीवन को समझने और उनकी आवाज़ को एक मंच देने की कोशिश की गई है। \\\n",
        "उत्तरार्द्ध सख्त तौर पर आरोपों को सफेद करने के उद्देश्य से सरकारी मुखपत्र के रूप में काम करता है। फिल्म पहले भाग में ऊंची उड़ान भरती है और दूसरे भाग में दुर्घटनाग्रस्त हो जाती है, क्योंकि यह इसकी ईमानदारी और मानवीय भावनाओं को खत्म कर देती है। \\\n",
        "मीडिया को दुर्भावनापूर्ण के रूप में पेश करना और यह संकेत देना कि वे असली वायरस हैं जिन्हें बंद करने की आवश्यकता है, फिल्म की सबसे कमजोर कड़ी है। 'यह जैव युद्ध नहीं है, यह एक सूचना युद्ध है', हमें बताया गया है। यह कथन कि मीडिया 'विदेशी शक्तियों' की कठपुतली है क्योंकि वे इसे वित्त पोषित करते हैं, एक असत्यापित व्हाट्स ऐप फॉरवर्ड की तरह लगता है।फिल्म कुछ पत्रकारों और उनकी विचारधाराओं को 'पूर्वाग्रही' कहती है लेकिन कहानी उसी एकतरफा मानसिकता का शिकार है।\\\n",
        "'सूअरों के साथ कभी कुश्ती मत लड़ो। आप दोनों गंदे हो जाते हैं, और सुअर को यह पसंद है' वाक्यांश का उपयोग यह बताने के लिए किया जाता है कि प्रेस कॉन्फ्रेंस क्यों आवश्यक नहीं हैं क्योंकि मीडिया केवल गलत सूचना फैलाता है। विरोधाभासी विचारों को पूरी तरह से खारिज करना और इसे भारत-विरोधी मोड़ देना काम नहीं करता है। षड्यंत्र के सिद्धांत जो अनुमान लगाते हैं कि क्या चीन ने जानबूझकर वायरस को लीक किया है, फार्मा लॉबी, मीडिया ट्रायल और विदेशी शक्तियों के साथ उसकी सांठगांठ, यह सब तथ्यात्मक से अधिक विचारहीन लगता है।हालाँकि फ़िल्म कुछ क्षेत्रों में अच्छा प्रदर्शन करती है। \\\n",
        " यह स्क्रिप्ट वैश्विक संकट के समय में वास्तविक पात्रों, उनकी दिन-प्रतिदिन की परेशानियों और कार्यस्थल की गतिशीलता को दर्शाती है। कहानी कहने से आंतरिक संचार, संगठनात्मक अराजकता और संघर्ष सही हो जाता है। फिल्म तकनीकी रूप से मजबूत है और अग्निहोत्री के हालिया काम से बेहतर है। डॉ. बलराम भार्गव (डीजी-आईसीएमआर) के रूप में नाना पाटेकर और डॉ. प्रिया अब्राहम, निदेशक-एनआईवी के रूप में पल्लवी जोशी एकदम परफेक्ट हैं। गिरिजा ओक गोडबोले डॉ. निवेदिता गुप्ता (आईसीएमआर) के रूप में प्रभावी हैं।जहां तक ​​भारतीय वैज्ञानिकों पर प्रकाश डालने की बात है तो यह फिल्म आकर्षक है। गंभीर वैश्विक संकट के समय आत्मनिर्भर भावना को बढ़ावा देने पर इसका जोर, जिसके कारण बड़े पैमाने पर मानव जीवन की हानि हुई, थोड़ा अपरिपक्व लगता है।\"\n",
        "overall_chain(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQT2vs9dBsxP",
        "outputId": "6f800027-fa7f-44e6-ae58-3ed24b7d4785"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Non-English_text': \"कोविड-19 का प्रकोप मानव इतिहास में हमेशा एक काला अध्याय रहेगा। हममें से कई लोगों ने अपने किसी प्रियजन या किसी जानने वाले को खो दिया है और हमने पहले कभी इतना असहाय महसूस नहीं किया। यह फिल्म विशेष रूप से उन लोगों के लिए प्रेरक हो सकती है जिन्हें महामारी के दौरान व्यक्तिगत क्षति का सामना करना पड़ा।कहानी कोवैक्सिन के चरण-दर-चरण निर्माण का अनुसरण करती है जिसे भारत बायोटेक द्वारा आईसीएमआर और नेशनल इंस्टीट्यूट ऑफ वायरोलॉजी (एनआईवी) के सहयोग से विकसित किया गया था। 2 घंटे, 40 मिनट की कठिन अवधि के दौरान, मेडिकल ड्रामा उन घटनाओं को फिर से दिखाता है जो चीन के वुहान में कोरोनोवायरस के प्रकोप के बाद भारत में सामने आईं। यह एक उपदेशात्मक खंडन के रूप में भी काम करता है, जो बड़ी संख्या में मानव जीवन लेने वाली महामारी से कथित तौर पर खराब तरीके से निपटने के लिए केंद्र सरकार की भारी आलोचना का सामना करता है। 'द वैक्सीन वॉर' को दो कहानियों में बांटा जा सकता है। पहले भाग में वैज्ञानिकों के जीवन को समझने और उनकी आवाज़ को एक मंच देने की कोशिश की गई है। उत्तरार्द्ध सख्त तौर पर आरोपों को सफेद करने के उद्देश्य से सरकारी मुखपत्र के रूप में काम करता है। फिल्म पहले भाग में ऊंची उड़ान भरती है और दूसरे भाग में दुर्घटनाग्रस्त हो जाती है, क्योंकि यह इसकी ईमानदारी और मानवीय भावनाओं को खत्म कर देती है। मीडिया को दुर्भावनापूर्ण के रूप में पेश करना और यह संकेत देना कि वे असली वायरस हैं जिन्हें बंद करने की आवश्यकता है, फिल्म की सबसे कमजोर कड़ी है। 'यह जैव युद्ध नहीं है, यह एक सूचना युद्ध है', हमें बताया गया है। यह कथन कि मीडिया 'विदेशी शक्तियों' की कठपुतली है क्योंकि वे इसे वित्त पोषित करते हैं, एक असत्यापित व्हाट्स ऐप फॉरवर्ड की तरह लगता है।फिल्म कुछ पत्रकारों और उनकी विचारधाराओं को 'पूर्वाग्रही' कहती है लेकिन कहानी उसी एकतरफा मानसिकता का शिकार है।'सूअरों के साथ कभी कुश्ती मत लड़ो। आप दोनों गंदे हो जाते हैं, और सुअर को यह पसंद है' वाक्यांश का उपयोग यह बताने के लिए किया जाता है कि प्रेस कॉन्फ्रेंस क्यों आवश्यक नहीं हैं क्योंकि मीडिया केवल गलत सूचना फैलाता है। विरोधाभासी विचारों को पूरी तरह से खारिज करना और इसे भारत-विरोधी मोड़ देना काम नहीं करता है। षड्यंत्र के सिद्धांत जो अनुमान लगाते हैं कि क्या चीन ने जानबूझकर वायरस को लीक किया है, फार्मा लॉबी, मीडिया ट्रायल और विदेशी शक्तियों के साथ उसकी सांठगांठ, यह सब तथ्यात्मक से अधिक विचारहीन लगता है।हालाँकि फ़िल्म कुछ क्षेत्रों में अच्छा प्रदर्शन करती है।  यह स्क्रिप्ट वैश्विक संकट के समय में वास्तविक पात्रों, उनकी दिन-प्रतिदिन की परेशानियों और कार्यस्थल की गतिशीलता को दर्शाती है। कहानी कहने से आंतरिक संचार, संगठनात्मक अराजकता और संघर्ष सही हो जाता है। फिल्म तकनीकी रूप से मजबूत है और अग्निहोत्री के हालिया काम से बेहतर है। डॉ. बलराम भार्गव (डीजी-आईसीएमआर) के रूप में नाना पाटेकर और डॉ. प्रिया अब्राहम, निदेशक-एनआईवी के रूप में पल्लवी जोशी एकदम परफेक्ट हैं। गिरिजा ओक गोडबोले डॉ. निवेदिता गुप्ता (आईसीएमआर) के रूप में प्रभावी हैं।जहां तक \\u200b\\u200bभारतीय वैज्ञानिकों पर प्रकाश डालने की बात है तो यह फिल्म आकर्षक है। गंभीर वैश्विक संकट के समय आत्मनिर्भर भावना को बढ़ावा देने पर इसका जोर, जिसके कारण बड़े पैमाने पर मानव जीवन की हानि हुई, थोड़ा अपरिपक्व लगता है।\",\n",
              " 'translated_text': \"The pandemic of COVID-19 will always remain a black chapter in human history. Many of us have lost our loved ones or someone we know, and we have never felt so helpless before. This film can be particularly inspiring for those who had to face personal loss during the epidemic. The story follows the development of the Covaxin vaccine, developed by Bharat Biotech in collaboration with the ICMR and the National Institute of Virology (NIV). During the difficult period of 2 hours and 40 minutes, the medical drama shows events that occurred in India after the outbreak of the coronavirus in Wuhan, China. It also serves as a critique, facing heavy criticism from the central government for poorly handling the epidemic that claimed many human lives. The Vaccine War can be divided into two stories. The first part attempts to understand the lives of scientists and give them a platform to voice their opinions. It works as a government paper to clear allegations rigidly. The film soars in the first half and crashes in the second half, as it ends up being dishonest and devoid of human emotions. Presenting the media as malicious and signaling that they need to be stopped is the weakest link in the film. The film calls some journalists and their ideologies 'prejudiced,' but the story is a victim of that same one-sided mentality. The use of the phrase, 'Don't fight with the pigs; you both get dirty, and the pig likes it,' is used to explain why press conferences are unnecessary because the media only spreads false information. Eliminating opposing ideas entirely and presenting it as anti-Indian does not work. The principle of conspiracy, guessing whether China deliberately leaked the virus, organized lobby, media trials, and foreign powers' involvement, all seem more factual than thoughtful. However, the film performs well in some areas. It showcases the real characters, their daily struggles, and workplace dynamics during a global crisis. Storytelling brings internal communication, organizational anarchy, and conflict correctly. The film is technically sound and better than Agnihotri's recent work. Nana Patekar as Dr. Balram Bhargava (DGI-ICMR) and Pallavi Joshi as Dr. Priya Abraham, Director-NIV are both perfect. Girija Oak Godbole is impressive as Dr. Nivedita Gupta (ICMR). As far as highlighting Indian scientists goes, this film is intriguing. However, during a grave global crisis, emphasizing self-reliance seems a little immature, which led to significant human losses.\",\n",
              " 'summary': 'The Vaccine War is a medical drama film that follows the development of the Covaxin vaccine during the COVID-19 pandemic in India. While it showcases the lives of scientists and their struggles during the crisis, it falls short in its second half, presenting the media as malicious and suggesting that opposing ideas should be eliminated. The film also emphasizes self-reliance, despite the significant human losses suffered during the pandemic. However, the film is technically impressive, with strong performances from Nana Patekar, Pallavi Joshi, and Girija Oak Godbole as the main characters.',\n",
              " 'sentiment_analysis': \"The sentiment in this text is mixed. The opening sentence expresses a negative sentiment towards the COVID-19 pandemic as a black chapter in human history. The author then expresses empathy for those who have lost loved ones, which is a sad sentiment. They go on to describe the film as inspiring and intriguing, which expresses a positive sentiment. However, the author is critical of the film's second half, which is a negative sentiment, and they take issue with the film's portrayal of the media, which is also negative. Overall, the sentiment is a mix of sadness, inspiration, and criticism.\",\n",
              " 'movie_theme': 'The main topic/theme of the movie review is a critique of a film called \"The Vaccine War\" that follows the development of the Covaxin vaccine in India during the COVID-19 pandemic. The review discusses the strengths and weaknesses of the film, including its portrayal of scientists and the Indian government\\'s response to the pandemic, as well as its portrayal of the media. The review also touches on the impact of the pandemic and the importance of understanding the human element in such crises.',\n",
              " 'reason': \"The author acknowledges the impact of the pandemic and the importance of understanding the human element in such crises, which is a thoughtful sentiment. They also praise the technical aspects of the film and the performances of the actors, which is a positive sentiment. However, they express disappointment with the film's portrayal of the media and its emphasis on self-reliance, which are negative sentiments. Overall, the sentiment is complex and nuanced, reflecting the author's mixed feelings about the film and its themes.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}